{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffee3f0f-2d9a-4c30-b097-adb47a09ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087306fd-e4c0-4bf3-a894-87bf19185528",
   "metadata": {},
   "source": [
    "# How Good is your model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc494e0-a0bd-4e9b-8c12-d3394a001712",
   "metadata": {},
   "source": [
    "# Classification Metrics\n",
    "* Measuring model performance with accuracy:\n",
    "    * fraction of correctly classified samples\n",
    "    * not always a useful metric\n",
    "### Class imbalance example: Emails\n",
    "* Spam classification\n",
    "    * 99% of emails are real and 1% are spam\n",
    "    \n",
    "* Could build a classifier that predicts ALL emails are real, thus:\n",
    "    * 99% accurate\n",
    "        * sounds good...\n",
    "    * But it's horrible at actually classifying spam\n",
    "    * fails its purpose\n",
    "* We thus need a more nuanced method to asses the effectiveness of our model\n",
    "### Diagnosing Classification Predictions\n",
    "* confusion matrix\n",
    "    * Provides accuracy\n",
    "        *  $ \\frac{tp\\ +\\ tn}{tp\\ +\\ tn\\ +fp\\ +\\ fn} $\n",
    "        * t:= true\n",
    "        * f:= false\n",
    "        * p:= positive\n",
    "        * n:= negative\n",
    "* Precision: \n",
    "    * $ \\frac{tp}{tp+fp} $\n",
    "    * positive predictive value\n",
    "* Recall: \n",
    "    * $ \\frac{tp\\}{tp\\ +\\ fn} $\n",
    "    * sensitivity\n",
    "* F1score: \n",
    "\n",
    "    *  $ 2* \\frac{\"precision\"\\ *\\ recall}{precision\\ +\\ recall} $\n",
    "    \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290c997e-2ed1-4c30-8fb3-a909240db154",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "diabetes.head()\n",
    "\n",
    "X = diabetes.drop('diabetes', axis=1).values\n",
    "\n",
    "y =diabetes.diabetes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24941f88-4941-4759-a631-cc9eb7bbbb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805f1da8-1924-47c8-baaa-4bfb639780c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904da776-ccbf-40af-93ba-85d832f72411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8150561429391034\n",
      "AUC scores computed using 5-fold cross-validation: [0.81240741 0.80777778 0.82555556 0.87283019 0.84471698]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278c55a-4858-4ce4-82f1-65e55c8d1616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
